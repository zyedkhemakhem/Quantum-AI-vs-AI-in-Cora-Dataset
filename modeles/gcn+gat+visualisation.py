# -*- coding: utf-8 -*-
"""gcn+gat+visualisation

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-A_nlVs7o7Tir_W0RhQOXwKDsMDJBBVw
"""

# We assume that PyTorch is already installed
import torch
torchversion = torch.__version__

# Install PyTorch Scatter, PyTorch Sparse, and PyTorch Geometric
# !pip install -q torch-scatter -f https://data.pyg.org/whl/torch-{torchversion}.html
# !pip install -q torch-sparse -f https://data.pyg.org/whl/torch-{torchversion}.html
# !pip install -q git+https://github.com/pyg-team/pytorch_geometric.git

# Numpy for matrices
import numpy as np
np.random.seed(0)

# Visualization
import networkx as nx
from sklearn.manifold import TSNE
import matplotlib.pyplot as plt

"""# Dataset"""

from torch_geometric.datasets import Planetoid
import pandas as pd

# Import dataset from PyTorch Geometric
dataset = Planetoid(root=".", name="Cora")

data = dataset[0]

# Print information about the dataset
print(f'Dataset: {dataset}')
print('-------------------')
print(f'Number of graphs: {len(dataset)}')
print(f'Number of nodes: {data.x.shape[0]}')
print(f'Number of features: {dataset.num_features}')
print(f'Number of classes: {dataset.num_classes}')

# Print information about the graph
print(f'\nGraph:')
print('------')
print(f'Edges are directed: {data.is_directed()}')
print(f'Graph has isolated nodes: {data.has_isolated_nodes()}')
print(f'Graph has loops: {data.has_self_loops()}')

# Convert node features to a DataFrame for better visualization
features_df = pd.DataFrame(data.x.numpy())
features_df['label'] = data.y.numpy()
print("\nDataset as a DataFrame (first 5 rows):")
print(features_df.head())

"""***Explication du Cora Dataset:***

**Les n≈ìuds** repr√©sentent des articles de recherche.

**Les ar√™tes (edges)** repr√©sentent les citations entre les articles.

**Les caract√©ristiques (features)** d√©crivent le contenu de chaque article.

**Les labels (√©tiquettes)** repr√©sentent le sujet de recherche de chaque article.

**Colonnes des caract√©ristiques (0 - 1432)**

Chaque article est d√©crit par 1 433 caract√©ristiques.

Ces caract√©ristiques sont binaires (0 ou 1).
Elles indiquent la pr√©sence (1) ou l'absence (0) d'un mot sp√©cifique dans l‚Äôarticle.

**Colonne "label" (√©tiquette)**

C'est la derni√®re colonne du tableau.
Elle indique le sujet de l‚Äôarticle.
Il y a 7 classes possibles (de 0 √† 6), correspondant √† 7 domaines de recherche.




---


**0**	 ==> Apprentissage automatique (Machine Learning)

**1**	==> R√©seaux neuronaux (Neural Networks)

**2**	==> Syst√®mes d'exploitation (Operating Systems)

**3**	==> Th√©orie des algorithmes (Theory)

**4**	==> Cryptographie (Cryptography)

**5**	==> Vision par ordinateur (Computer Vision)

**6**	==> Syst√®mes de base de donn√©es (Database)

---
"""

from torch_geometric.utils import remove_isolated_nodes

isolated = (remove_isolated_nodes(data['edge_index'])[2] == False).sum(dim=0).item()
print(f'Number of isolated nodes = {isolated}')

"""# Plot dataset"""

from torch_geometric.utils import to_networkx

G = to_networkx(data, to_undirected=True)
plt.figure(figsize=(18,18))
plt.axis('off')
nx.draw_networkx(G,
                pos=nx.spring_layout(G, seed=0),
                with_labels=False,
                node_size=50,
                node_color=data.y,
                width=2,
                edge_color="grey"
                )
plt.show()

"""**Output: visualisation graphique du r√©seau de citations Cora :**


*   Chaque n≈ìud repr√©sente un article.

*   Chaque ar√™te repr√©sente une citation entre deux articles.

*   Les n≈ìuds ont diff√©rentes couleurs selon leur sujet de recherche.

*   La disposition du graphe sera organis√©e selon l‚Äôalgorithme Spring Layout.

# Plot node degrees
"""

from torch_geometric.utils import degree
from collections import Counter

# Get list of degrees for each node
degrees = degree(data.edge_index[0]).numpy()

# Count the number of nodes for each degree
numbers = Counter(degrees)

# Bar plot
fig, ax = plt.subplots(figsize=(18, 7))
ax.set_xlabel('Node degree')
ax.set_ylabel('Number of nodes')
plt.bar(numbers.keys(),
        numbers.values(),
        color='#0A047A')

"""Cette cellule sert √† analyser et visualiser la distribution des degr√©s des n≈ìuds dans le graphe Cora.

Le degr√© d‚Äôun n≈ìud repr√©sente le nombre de connexions (ar√™tes) qu'il a avec d'autres n≈ìuds.

**Output: un histogramme o√π :**


*   L‚Äôaxe X repr√©sente le degr√© des n≈ìuds (nombre de connexions d‚Äôun n≈ìud).
*   L‚Äôaxe Y repr√©sente le nombre de n≈ìuds ayant ce degr√©.

les graphes de citation Cora suivent une loi de puissance :


*   Peu de n≈ìuds ont un grand nombre de connexions (hubs).
*   Beaucoup de n≈ìuds ont peu de connexions.

# Implement GAT vs. GCN
"""

import torch
import torch.nn.functional as F
from torch_geometric.nn import GCNConv, GATv2Conv
import torch.nn as nn

# --- Mod√®le GCN avec trois couches ---
class GCN(torch.nn.Module):
    """Graph Convolutional Network with three layers:
       Transformation: dim_in -> dim_g -> dim_h -> dim_out
    """
    def __init__(self, dim_in, dim_g, dim_h, dim_out):
        super().__init__()
        self.gcn1 = GCNConv(dim_in, dim_g)
        self.gcn2 = GCNConv(dim_g, dim_h)
        self.gcn3 = GCNConv(dim_h, dim_out)
        self.optimizer = torch.optim.Adam(self.parameters(), lr=0.01, weight_decay=1e-3)

    def forward(self, x, edge_index):
        x = F.dropout(x, p=0.6, training=self.training)
        x = self.gcn1(x, edge_index)
        x = torch.relu(x)
        x = F.dropout(x, p=0.6, training=self.training)
        x = self.gcn2(x, edge_index)
        x = torch.relu(x)
        x = F.dropout(x, p=0.6, training=self.training)
        x = self.gcn3(x, edge_index)
        return x, F.log_softmax(x, dim=1)

# --- Mod√®le GAT avec trois couches ---
class GAT(torch.nn.Module):
    """Graph Attention Network with three layers using GATv2Conv:
       Transformation: dim_in -> dim_g -> dim_h -> dim_out
    """
    def __init__(self, dim_in, dim_g, dim_h, dim_out, heads1=8, heads2=8, heads3=1):
        super().__init__()
        # Premi√®re couche : de dim_in √† dim_g (par t√™te), sortie: dim_g * heads1
        self.gat1 = GATv2Conv(dim_in, dim_g, heads=heads1)
        # Deuxi√®me couche : de dim_g * heads1 √† dim_h (par t√™te), sortie: dim_h * heads2
        self.gat2 = GATv2Conv(dim_g * heads1, dim_h, heads=heads2)
        # Troisi√®me couche : de dim_h * heads2 √† dim_out (avec heads3)
        self.gat3 = GATv2Conv(dim_h * heads2, dim_out, heads=heads3)
        self.optimizer = torch.optim.Adam(self.parameters(), lr=0.005, weight_decay=5e-4)

    def forward(self, x, edge_index):
        x = F.dropout(x, p=0.6, training=self.training)
        x = self.gat1(x, edge_index)
        x = F.elu(x)
        x = F.dropout(x, p=0.6, training=self.training)
        x = self.gat2(x, edge_index)
        x = F.elu(x)
        x = F.dropout(x, p=0.6, training=self.training)
        x = self.gat3(x, edge_index)
        return x, F.log_softmax(x, dim=1)

# --- Fonctions utilitaires ---
def accuracy(pred_y, y):
    """Calcule l'accuracy."""
    return ((pred_y == y).sum() / len(y)).item()

def train(model, data, epochs=200, patience=30):
    criterion = torch.nn.CrossEntropyLoss()
    optimizer = model.optimizer
    best_val_loss = float('inf')
    patience_counter = 0

    model.train()
    for epoch in range(epochs+1):
        optimizer.zero_grad()
        _, out = model(data.x, data.edge_index)
        loss = criterion(out[data.train_mask], data.y[data.train_mask])
        loss.backward()
        optimizer.step()

        val_loss = criterion(out[data.val_mask], data.y[data.val_mask])
        val_acc = accuracy(out[data.val_mask].argmax(dim=1), data.y[data.val_mask])

        if val_loss < best_val_loss:
            best_val_loss = val_loss
            patience_counter = 0
        else:
            patience_counter += 1

        if patience_counter == patience:
            print(f"Stopping early at epoch {epoch}")
            break

        if epoch % 10 == 0:
            train_acc = accuracy(out[data.train_mask].argmax(dim=1), data.y[data.train_mask])
            print(f'Epoch {epoch:>3} | Train Loss: {loss:.3f} | Train Acc: {train_acc*100:>6.2f}% | '
                  f'Val Loss: {val_loss:.2f} | Val Acc: {val_acc*100:.2f}%')
    return model

def test(model, data):
    model.eval()
    _, out = model(data.x, data.edge_index)
    test_acc = accuracy(out[data.test_mask].argmax(dim=1), data.y[data.test_mask])
    print(f"Test Accuracy: {test_acc*100:.2f}%")
    return test_acc

print("=== GCN avec 3 couches ===")
gcn_model = GCN(dim_in=dataset.num_features, dim_g=256, dim_h=128, dim_out=dataset.num_classes)
print(gcn_model)
train(gcn_model, data)
test(gcn_model, data)

print("\n=== GAT avec 3 couches ===")
gat_model = GAT(dim_in=dataset.num_features, dim_g=8, dim_h=16, dim_out=dataset.num_classes, heads1=8, heads2=8, heads3=1)
print(gat_model)
train(gat_model, data)
test(gat_model, data)

"""**Architecture GCN :**


*   Deux couches GCNConv :

  *   GCNConv(dim_in, dim_h): premi√®re couche convolutive (entr√©e ‚Üí couches cach√©es).
  *   GCNConv(dim_h, dim_out): deuxi√®me couche convolutive (couches cach√©es ‚Üí sortie).

*   Optimiseur Adam avec :

  *   lr=0.01 : Taux d‚Äôapprentissage.
  *   weight_decay=5e-4 : R√©gularisation L2 pour √©viter l‚Äôoverfitting.

**Propagation avant (forward) :**


1.   Applique un dropout (p=0.5) pour √©viter l‚Äôoverfitting.
2.   Passe les donn√©es dans gcn1.
3. Activation ReLU pour introduire de la non-lin√©arit√©.
4. Encore un dropout (p=0.5).
5. Passe les donn√©es dans gcn2.
6. Retourne les logits + softmax logarithmique (F.log_softmax).

**Architecture GAT :**


*   Deux couches GAT :

  *   GATv2Conv(dim_in, dim_h, heads=8): 1√®re couche avec 8 t√™tes d'attention ‚Üí Feature extraction. ==> Applique 8 m√©canismes d‚Äôattention en parall√®le.
  *   GATv2Conv(dim_h*heads, dim_out, heads=1):2√®me couche avec 1 t√™te ‚Üí Classification. ==> Combine les 8 sorties en une seule (agr√©gation).

**Propagation avant (forward) :**


1.   Dropout (p=0.6) plus √©lev√© que dans GCN pour r√©gularisation.
2.   Passe les donn√©es dans gat1.
3.   Activation ELU au lieu de ReLU (plus douce pour GAT).
4.   Encore un dropout (p=0.6).
5.   Passe les donn√©es dans gat2.
6.   Retourne les logits + softmax logarithmique (F.log_softmax).

### üìå Explication des Hyperparam√®tres

| **Hyperparam√®tre**  | **GCN** | **GAT** | **R√¥le** |
|---------------------|--------|--------|---------|
| `dim_in`           | Entr√©e  | Entr√©e  | Nombre de **features par n≈ìud** |
| `dim_h`            | Cach√©   | Cach√©   | Taille de la **couche cach√©e** |
| `dim_out`          | Sortie  | Sortie  | Nombre de **classes** (7 pour Cora) |
| `lr`              | 0.01    | 0.005   | Taux d‚Äô**apprentissage** |
| `weight_decay`     | 5e-4    | 5e-4    | **R√©gularisation** L2 |
| `dropout`         | 0.5     | 0.6     | Pr√©vient l‚Äô**overfitting** |
| `heads`           | ‚ùå      | 8       | Nombre de **t√™tes d‚Äôattention** dans GAT |

# Train GCN
"""

gat = GAT(dataset.num_features, 8, 16, dataset.num_classes)
print(gat)

# Train the GAT model
train(gat, data)

# Test the GAT model
acc = test(gat, data)
print(f'\nGAT test accuracy: {acc*100:.2f}%\n')

"""**Output:**


1.  L'architecture du mod√®le GCN.
2.  L'√©volution de la loss et de l'accuracy pendant l'entra√Ænement (tous les 10 epochs).
3.   L'accuracy finale du mod√®le sur les donn√©es de test.

# Train GAT
"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# # Create GAT model
# gat = GAT(dataset.num_features, 8, dataset.num_classes)
# print(gat)
# 
# # Train
# train(gat, data)
# 
# # Test
# acc = test(gat, data)
# print(f'\nGAT test accuracy: {acc*100:.2f}%\n')

"""**Output:**


1.   L'architecture du mod√®le GAT.
2.   L'√©volution de la loss et de l'accuracy pendant l'entra√Ænement.
3.   L'accuracy finale du mod√®le sur les donn√©es de test.

# t-SNE plots
"""

# Initialize new untrained model
untrained_gat = GAT(dataset.num_features, 8,16, dataset.num_classes)

# Get embeddings
h, _ = untrained_gat(data.x, data.edge_index)

# Train TSNE
tsne = TSNE(n_components=2, learning_rate='auto',
         init='pca').fit_transform(h.detach())

# Plot TSNE
plt.figure(figsize=(10, 10))
plt.axis('off')
plt.scatter(tsne[:, 0], tsne[:, 1], s=50, c=data.y)
plt.show()

"""Cette cellule sert √† visualiser les embeddings des n≈ìuds g√©n√©r√©s par un mod√®le GAT **non entra√Æn√©** √† l‚Äôaide de **TSNE** (t-Distributed Stochastic Neighbor Embedding), une technique de r√©duction de dimensionnalit√©.

**Output :** un graphique TSNE o√π chaque point repr√©sente un n≈ìud color√© selon sa classe r√©elle.

==> √âtant donn√© que le mod√®le n'est pas entra√Æn√©, les points seront r√©partis de mani√®re chaotique.
"""

# Get embeddings
h, _ = gat(data.x, data.edge_index)

# Train TSNE
tsne = TSNE(n_components=2, learning_rate='auto',
         init='pca').fit_transform(h.detach())

# Plot TSNE
plt.figure(figsize=(10, 10))
plt.axis('off')
plt.scatter(tsne[:, 0], tsne[:, 1], s=50, c=data.y)
plt.show()

"""Cette cellule effectue une visualisation TSNE des embeddings g√©n√©r√©s par le mod√®le GAT entra√Æn√©. Les embeddings sont mieux organis√©s et montrent une meilleure s√©paration des classes.

**Output:** un graphique TSNE montrant comment les embeddings sont organis√©s apr√®s l'entra√Ænement du mod√®le GAT.
==> Les points appartenant √† la m√™me classe sont mieux regroup√©s, et il y a une meilleure s√©paration des classes.

# Plot accuracy for each node degree
"""

from torch_geometric.utils import degree

# Get model's classifications
_, out = gat(data.x, data.edge_index)

# Calculate the degree of each node
degrees = degree(data.edge_index[0]).numpy()

# Store accuracy scores and sample sizes
accuracies = []
sizes = []

# Accuracy for degrees between 0 and 5
for i in range(0, 6):
  mask = np.where(degrees == i)[0]
  accuracies.append(accuracy(out.argmax(dim=1)[mask], data.y[mask]))
  sizes.append(len(mask))

# Accuracy for degrees > 5
mask = np.where(degrees > 5)[0]
accuracies.append(accuracy(out.argmax(dim=1)[mask], data.y[mask]))
sizes.append(len(mask))

# Bar plot
fig, ax = plt.subplots(figsize=(18, 9))
ax.set_xlabel('Node degree')
ax.set_ylabel('Accuracy score')
plt.bar(['0','1','2','3','4','5','>5'],
        accuracies,
        color='#0A047A')
for i in range(0, 7):
    plt.text(i, accuracies[i], f'{accuracies[i]*100:.2f}%',
             ha='center', color='#0A047A')
for i in range(0, 7):
    plt.text(i, accuracies[i]//2, sizes[i],
             ha='center', color='white')
