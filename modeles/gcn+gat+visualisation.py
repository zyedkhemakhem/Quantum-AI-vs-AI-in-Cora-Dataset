# -*- coding: utf-8 -*-
"""gcn+gat+visualisation

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-A_nlVs7o7Tir_W0RhQOXwKDsMDJBBVw
"""

# We assume that PyTorch is already installed
import torch
torchversion = torch.__version__

# Install PyTorch Scatter, PyTorch Sparse, and PyTorch Geometric
# !pip install -q torch-scatter -f https://data.pyg.org/whl/torch-{torchversion}.html
# !pip install -q torch-sparse -f https://data.pyg.org/whl/torch-{torchversion}.html
# !pip install -q git+https://github.com/pyg-team/pytorch_geometric.git

# Numpy for matrices
import numpy as np
np.random.seed(0)

# Visualization
import networkx as nx
from sklearn.manifold import TSNE
import matplotlib.pyplot as plt

"""# Dataset"""

from torch_geometric.datasets import Planetoid
import pandas as pd

# Import dataset from PyTorch Geometric
dataset = Planetoid(root=".", name="Cora")

data = dataset[0]

# Print information about the dataset
print(f'Dataset: {dataset}')
print('-------------------')
print(f'Number of graphs: {len(dataset)}')
print(f'Number of nodes: {data.x.shape[0]}')
print(f'Number of features: {dataset.num_features}')
print(f'Number of classes: {dataset.num_classes}')

# Print information about the graph
print(f'\nGraph:')
print('------')
print(f'Edges are directed: {data.is_directed()}')
print(f'Graph has isolated nodes: {data.has_isolated_nodes()}')
print(f'Graph has loops: {data.has_self_loops()}')

# Convert node features to a DataFrame for better visualization
features_df = pd.DataFrame(data.x.numpy())
features_df['label'] = data.y.numpy()
print("\nDataset as a DataFrame (first 5 rows):")
print(features_df.head())

"""***Explication du Cora Dataset:***

**Les nœuds** représentent des articles de recherche.

**Les arêtes (edges)** représentent les citations entre les articles.

**Les caractéristiques (features)** décrivent le contenu de chaque article.

**Les labels (étiquettes)** représentent le sujet de recherche de chaque article.

**Colonnes des caractéristiques (0 - 1432)**

Chaque article est décrit par 1 433 caractéristiques.

Ces caractéristiques sont binaires (0 ou 1).
Elles indiquent la présence (1) ou l'absence (0) d'un mot spécifique dans l’article.

**Colonne "label" (étiquette)**

C'est la dernière colonne du tableau.
Elle indique le sujet de l’article.
Il y a 7 classes possibles (de 0 à 6), correspondant à 7 domaines de recherche.




---


**0**	 ==> Apprentissage automatique (Machine Learning)

**1**	==> Réseaux neuronaux (Neural Networks)

**2**	==> Systèmes d'exploitation (Operating Systems)

**3**	==> Théorie des algorithmes (Theory)

**4**	==> Cryptographie (Cryptography)

**5**	==> Vision par ordinateur (Computer Vision)

**6**	==> Systèmes de base de données (Database)

---
"""

from torch_geometric.utils import remove_isolated_nodes

isolated = (remove_isolated_nodes(data['edge_index'])[2] == False).sum(dim=0).item()
print(f'Number of isolated nodes = {isolated}')

"""# Plot dataset"""

from torch_geometric.utils import to_networkx

G = to_networkx(data, to_undirected=True)
plt.figure(figsize=(18,18))
plt.axis('off')
nx.draw_networkx(G,
                pos=nx.spring_layout(G, seed=0),
                with_labels=False,
                node_size=50,
                node_color=data.y,
                width=2,
                edge_color="grey"
                )
plt.show()

"""**Output: visualisation graphique du réseau de citations Cora :**


*   Chaque nœud représente un article.

*   Chaque arête représente une citation entre deux articles.

*   Les nœuds ont différentes couleurs selon leur sujet de recherche.

*   La disposition du graphe sera organisée selon l’algorithme Spring Layout.

# Plot node degrees
"""

from torch_geometric.utils import degree
from collections import Counter

# Get list of degrees for each node
degrees = degree(data.edge_index[0]).numpy()

# Count the number of nodes for each degree
numbers = Counter(degrees)

# Bar plot
fig, ax = plt.subplots(figsize=(18, 7))
ax.set_xlabel('Node degree')
ax.set_ylabel('Number of nodes')
plt.bar(numbers.keys(),
        numbers.values(),
        color='#0A047A')

"""Cette cellule sert à analyser et visualiser la distribution des degrés des nœuds dans le graphe Cora.

Le degré d’un nœud représente le nombre de connexions (arêtes) qu'il a avec d'autres nœuds.

**Output: un histogramme où :**


*   L’axe X représente le degré des nœuds (nombre de connexions d’un nœud).
*   L’axe Y représente le nombre de nœuds ayant ce degré.

les graphes de citation Cora suivent une loi de puissance :


*   Peu de nœuds ont un grand nombre de connexions (hubs).
*   Beaucoup de nœuds ont peu de connexions.

# Implement GAT vs. GCN
"""

import torch
import torch.nn.functional as F
from torch_geometric.nn import GCNConv, GATv2Conv
import torch.nn as nn

# --- Modèle GCN avec trois couches ---
class GCN(torch.nn.Module):
    """Graph Convolutional Network with three layers:
       Transformation: dim_in -> dim_g -> dim_h -> dim_out
    """
    def __init__(self, dim_in, dim_g, dim_h, dim_out):
        super().__init__()
        self.gcn1 = GCNConv(dim_in, dim_g)
        self.gcn2 = GCNConv(dim_g, dim_h)
        self.gcn3 = GCNConv(dim_h, dim_out)
        self.optimizer = torch.optim.Adam(self.parameters(), lr=0.01, weight_decay=1e-3)

    def forward(self, x, edge_index):
        x = F.dropout(x, p=0.6, training=self.training)
        x = self.gcn1(x, edge_index)
        x = torch.relu(x)
        x = F.dropout(x, p=0.6, training=self.training)
        x = self.gcn2(x, edge_index)
        x = torch.relu(x)
        x = F.dropout(x, p=0.6, training=self.training)
        x = self.gcn3(x, edge_index)
        return x, F.log_softmax(x, dim=1)

# --- Modèle GAT avec trois couches ---
class GAT(torch.nn.Module):
    """Graph Attention Network with three layers using GATv2Conv:
       Transformation: dim_in -> dim_g -> dim_h -> dim_out
    """
    def __init__(self, dim_in, dim_g, dim_h, dim_out, heads1=8, heads2=8, heads3=1):
        super().__init__()
        # Première couche : de dim_in à dim_g (par tête), sortie: dim_g * heads1
        self.gat1 = GATv2Conv(dim_in, dim_g, heads=heads1)
        # Deuxième couche : de dim_g * heads1 à dim_h (par tête), sortie: dim_h * heads2
        self.gat2 = GATv2Conv(dim_g * heads1, dim_h, heads=heads2)
        # Troisième couche : de dim_h * heads2 à dim_out (avec heads3)
        self.gat3 = GATv2Conv(dim_h * heads2, dim_out, heads=heads3)
        self.optimizer = torch.optim.Adam(self.parameters(), lr=0.005, weight_decay=5e-4)

    def forward(self, x, edge_index):
        x = F.dropout(x, p=0.6, training=self.training)
        x = self.gat1(x, edge_index)
        x = F.elu(x)
        x = F.dropout(x, p=0.6, training=self.training)
        x = self.gat2(x, edge_index)
        x = F.elu(x)
        x = F.dropout(x, p=0.6, training=self.training)
        x = self.gat3(x, edge_index)
        return x, F.log_softmax(x, dim=1)

# --- Fonctions utilitaires ---
def accuracy(pred_y, y):
    """Calcule l'accuracy."""
    return ((pred_y == y).sum() / len(y)).item()

def train(model, data, epochs=200, patience=30):
    criterion = torch.nn.CrossEntropyLoss()
    optimizer = model.optimizer
    best_val_loss = float('inf')
    patience_counter = 0

    model.train()
    for epoch in range(epochs+1):
        optimizer.zero_grad()
        _, out = model(data.x, data.edge_index)
        loss = criterion(out[data.train_mask], data.y[data.train_mask])
        loss.backward()
        optimizer.step()

        val_loss = criterion(out[data.val_mask], data.y[data.val_mask])
        val_acc = accuracy(out[data.val_mask].argmax(dim=1), data.y[data.val_mask])

        if val_loss < best_val_loss:
            best_val_loss = val_loss
            patience_counter = 0
        else:
            patience_counter += 1

        if patience_counter == patience:
            print(f"Stopping early at epoch {epoch}")
            break

        if epoch % 10 == 0:
            train_acc = accuracy(out[data.train_mask].argmax(dim=1), data.y[data.train_mask])
            print(f'Epoch {epoch:>3} | Train Loss: {loss:.3f} | Train Acc: {train_acc*100:>6.2f}% | '
                  f'Val Loss: {val_loss:.2f} | Val Acc: {val_acc*100:.2f}%')
    return model

def test(model, data):
    model.eval()
    _, out = model(data.x, data.edge_index)
    test_acc = accuracy(out[data.test_mask].argmax(dim=1), data.y[data.test_mask])
    print(f"Test Accuracy: {test_acc*100:.2f}%")
    return test_acc

print("=== GCN avec 3 couches ===")
gcn_model = GCN(dim_in=dataset.num_features, dim_g=256, dim_h=128, dim_out=dataset.num_classes)
print(gcn_model)
train(gcn_model, data)
test(gcn_model, data)

print("\n=== GAT avec 3 couches ===")
gat_model = GAT(dim_in=dataset.num_features, dim_g=8, dim_h=16, dim_out=dataset.num_classes, heads1=8, heads2=8, heads3=1)
print(gat_model)
train(gat_model, data)
test(gat_model, data)

"""**Architecture GCN :**


*   Deux couches GCNConv :

  *   GCNConv(dim_in, dim_h): première couche convolutive (entrée → couches cachées).
  *   GCNConv(dim_h, dim_out): deuxième couche convolutive (couches cachées → sortie).

*   Optimiseur Adam avec :

  *   lr=0.01 : Taux d’apprentissage.
  *   weight_decay=5e-4 : Régularisation L2 pour éviter l’overfitting.

**Propagation avant (forward) :**


1.   Applique un dropout (p=0.5) pour éviter l’overfitting.
2.   Passe les données dans gcn1.
3. Activation ReLU pour introduire de la non-linéarité.
4. Encore un dropout (p=0.5).
5. Passe les données dans gcn2.
6. Retourne les logits + softmax logarithmique (F.log_softmax).

**Architecture GAT :**


*   Deux couches GAT :

  *   GATv2Conv(dim_in, dim_h, heads=8): 1ère couche avec 8 têtes d'attention → Feature extraction. ==> Applique 8 mécanismes d’attention en parallèle.
  *   GATv2Conv(dim_h*heads, dim_out, heads=1):2ème couche avec 1 tête → Classification. ==> Combine les 8 sorties en une seule (agrégation).

**Propagation avant (forward) :**


1.   Dropout (p=0.6) plus élevé que dans GCN pour régularisation.
2.   Passe les données dans gat1.
3.   Activation ELU au lieu de ReLU (plus douce pour GAT).
4.   Encore un dropout (p=0.6).
5.   Passe les données dans gat2.
6.   Retourne les logits + softmax logarithmique (F.log_softmax).

### 📌 Explication des Hyperparamètres

| **Hyperparamètre**  | **GCN** | **GAT** | **Rôle** |
|---------------------|--------|--------|---------|
| `dim_in`           | Entrée  | Entrée  | Nombre de **features par nœud** |
| `dim_h`            | Caché   | Caché   | Taille de la **couche cachée** |
| `dim_out`          | Sortie  | Sortie  | Nombre de **classes** (7 pour Cora) |
| `lr`              | 0.01    | 0.005   | Taux d’**apprentissage** |
| `weight_decay`     | 5e-4    | 5e-4    | **Régularisation** L2 |
| `dropout`         | 0.5     | 0.6     | Prévient l’**overfitting** |
| `heads`           | ❌      | 8       | Nombre de **têtes d’attention** dans GAT |

# Train GCN
"""

gat = GAT(dataset.num_features, 8, 16, dataset.num_classes)
print(gat)

# Train the GAT model
train(gat, data)

# Test the GAT model
acc = test(gat, data)
print(f'\nGAT test accuracy: {acc*100:.2f}%\n')

"""**Output:**


1.  L'architecture du modèle GCN.
2.  L'évolution de la loss et de l'accuracy pendant l'entraînement (tous les 10 epochs).
3.   L'accuracy finale du modèle sur les données de test.

# Train GAT
"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# # Create GAT model
# gat = GAT(dataset.num_features, 8, dataset.num_classes)
# print(gat)
# 
# # Train
# train(gat, data)
# 
# # Test
# acc = test(gat, data)
# print(f'\nGAT test accuracy: {acc*100:.2f}%\n')

"""**Output:**


1.   L'architecture du modèle GAT.
2.   L'évolution de la loss et de l'accuracy pendant l'entraînement.
3.   L'accuracy finale du modèle sur les données de test.

# t-SNE plots
"""

# Initialize new untrained model
untrained_gat = GAT(dataset.num_features, 8,16, dataset.num_classes)

# Get embeddings
h, _ = untrained_gat(data.x, data.edge_index)

# Train TSNE
tsne = TSNE(n_components=2, learning_rate='auto',
         init='pca').fit_transform(h.detach())

# Plot TSNE
plt.figure(figsize=(10, 10))
plt.axis('off')
plt.scatter(tsne[:, 0], tsne[:, 1], s=50, c=data.y)
plt.show()

"""Cette cellule sert à visualiser les embeddings des nœuds générés par un modèle GAT **non entraîné** à l’aide de **TSNE** (t-Distributed Stochastic Neighbor Embedding), une technique de réduction de dimensionnalité.

**Output :** un graphique TSNE où chaque point représente un nœud coloré selon sa classe réelle.

==> Étant donné que le modèle n'est pas entraîné, les points seront répartis de manière chaotique.
"""

# Get embeddings
h, _ = gat(data.x, data.edge_index)

# Train TSNE
tsne = TSNE(n_components=2, learning_rate='auto',
         init='pca').fit_transform(h.detach())

# Plot TSNE
plt.figure(figsize=(10, 10))
plt.axis('off')
plt.scatter(tsne[:, 0], tsne[:, 1], s=50, c=data.y)
plt.show()

"""Cette cellule effectue une visualisation TSNE des embeddings générés par le modèle GAT entraîné. Les embeddings sont mieux organisés et montrent une meilleure séparation des classes.

**Output:** un graphique TSNE montrant comment les embeddings sont organisés après l'entraînement du modèle GAT.
==> Les points appartenant à la même classe sont mieux regroupés, et il y a une meilleure séparation des classes.

# Plot accuracy for each node degree
"""

from torch_geometric.utils import degree

# Get model's classifications
_, out = gat(data.x, data.edge_index)

# Calculate the degree of each node
degrees = degree(data.edge_index[0]).numpy()

# Store accuracy scores and sample sizes
accuracies = []
sizes = []

# Accuracy for degrees between 0 and 5
for i in range(0, 6):
  mask = np.where(degrees == i)[0]
  accuracies.append(accuracy(out.argmax(dim=1)[mask], data.y[mask]))
  sizes.append(len(mask))

# Accuracy for degrees > 5
mask = np.where(degrees > 5)[0]
accuracies.append(accuracy(out.argmax(dim=1)[mask], data.y[mask]))
sizes.append(len(mask))

# Bar plot
fig, ax = plt.subplots(figsize=(18, 9))
ax.set_xlabel('Node degree')
ax.set_ylabel('Accuracy score')
plt.bar(['0','1','2','3','4','5','>5'],
        accuracies,
        color='#0A047A')
for i in range(0, 7):
    plt.text(i, accuracies[i], f'{accuracies[i]*100:.2f}%',
             ha='center', color='#0A047A')
for i in range(0, 7):
    plt.text(i, accuracies[i]//2, sizes[i],
             ha='center', color='white')
